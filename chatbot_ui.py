import streamlit as st
import subprocess

# -----------------------------
# Configuration de la page
# -----------------------------
st.set_page_config(page_title="Mini Chatbot Mistral", page_icon="ğŸ¤–")
st.title("ğŸ’¬ Mini Chatbot â€” Lab 5 (Ollama + Streamlit)")
st.write("Pose une question Ã  ton agent Mistral local ! Tape une phrase, choisis la tempÃ©rature, et clique sur *Envoyer*.")

# -----------------------------
# Fonction pour appeler Ollama
# -----------------------------
def run_ollama(prompt):
    """
    ExÃ©cute Ollama (modÃ¨le Mistral) depuis Python et renvoie la rÃ©ponse.
    GÃ¨re l'encodage et les erreurs pour Windows.
    """
    try:
        r = subprocess.run(
            ["ollama", "run", "mistral", prompt],
            capture_output=True,
            text=True,
            encoding="utf-8",
            errors="ignore"
        )

        if r.returncode != 0:
            return f"âŒ Erreur Ollama : {r.stderr.strip()}"
        return r.stdout.strip() if r.stdout else "âš ï¸ Pas de rÃ©ponse du modÃ¨le."

    except Exception as e:
        return f"âŒ Erreur Python : {e}"

# -----------------------------
# Interface utilisateur Streamlit
# -----------------------------
st.divider()
prompt = st.text_area("ğŸ’­ Entrez votre question :", placeholder="Ex: Explique-moi ce quâ€™est un agent dâ€™IA.")
temperature = st.slider("ğŸ”¥ TempÃ©rature (crÃ©ativitÃ© simulÃ©e)", 0.1, 1.0, 0.7, 0.1)

if st.button("ğŸš€ Envoyer la requÃªte"):
    if prompt.strip() == "":
        st.warning("âš ï¸ Merci dâ€™Ã©crire une question avant dâ€™envoyer.")
    else:
        st.info(f"TempÃ©rature simulÃ©e : **{temperature}**")
        with st.spinner("ğŸ§  RÃ©flexion en cours..."):
            response = run_ollama(prompt)
        st.success("âœ… RÃ©ponse reÃ§ue :")
        st.write(response)

st.divider()
st.caption("ğŸ’¡ PropulsÃ© par Ollama + Mistral | Module 1 â€” Ydays M1 IA")
